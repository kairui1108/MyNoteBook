# 学习笔记

## redis实战项目

### 短信登录

### 缓存

- 添加缓存
- 缓存更新策略
- 双写一致
  - 查询时，如果未命中则查询数据库，并写入缓存
  - 有修改时，修改后删除缓存
- 缓存穿透（缓存和数据库都不存在数据，请求永远到达数据库）
  - 缓存空对象
  - 博隆过滤
- 缓存雪崩（大量缓存同时过期）
  - 添加随机ttl值
  - redis集群
  - 限流降级
  - 多级缓存
- 缓存击穿（热点key，高并发访问且重建复杂突然失效）
  - 互斥锁
  - 逻辑过期

```java
@Slf4j
@Component
public class CacheClient {

    private final StringRedisTemplate stringRedisTemplate;

    private static final ExecutorService CACHE_REBUILD_EXECUTOR = Executors.newFixedThreadPool(10);

    public CacheClient(StringRedisTemplate stringRedisTemplate) {
        this.stringRedisTemplate = stringRedisTemplate;
    }

    public void set(String key, Object value, Long time, TimeUnit unit) {
        stringRedisTemplate.opsForValue().set(key, JSONUtil.toJsonStr(value), time, unit);
    }

    
    public void setWithLogicalExpire(String key, Object value, Long time, TimeUnit unit) {
        // 设置逻辑过期
        RedisData redisData = new RedisData();
        redisData.setData(value);
        redisData.setExpireTime(LocalDateTime.now().plusSeconds(unit.toSeconds(time)));
        // 写入Redis
        stringRedisTemplate.opsForValue().set(key, JSONUtil.toJsonStr(redisData));
    }

    // 空对象，缓存穿透
    public <R,ID> R queryWithPassThrough(
            String keyPrefix, ID id, Class<R> type, Function<ID, R> dbFallback, Long time, TimeUnit unit){
        String key = keyPrefix + id;
        // 1.从redis查询商铺缓存
        String json = stringRedisTemplate.opsForValue().get(key);
        // 2.判断是否存在
        if (StrUtil.isNotBlank(json)) {
            // 3.存在，直接返回
            return JSONUtil.toBean(json, type);
        }
        // 判断命中的是否是空值
        if (json != null) {
            // 返回一个错误信息
            return null;
        }

        // 4.不存在，根据id查询数据库
        R r = dbFallback.apply(id);
        // 5.不存在，返回错误
        if (r == null) {
            // 将空值写入redis
            stringRedisTemplate.opsForValue().set(key, "", CACHE_NULL_TTL, TimeUnit.MINUTES);
            // 返回错误信息
            return null;
        }
        // 6.存在，写入redis
        this.set(key, r, time, unit);
        return r;
    }

    // 缓存击穿
    public <R, ID> R queryWithLogicalExpire(
            String keyPrefix, ID id, Class<R> type, Function<ID, R> dbFallback, Long time, TimeUnit unit) {
        String key = keyPrefix + id;
        // 1.从redis查询商铺缓存
        String json = stringRedisTemplate.opsForValue().get(key);
        // 2.判断是否存在
        if (StrUtil.isBlank(json)) {
            // 3.存在，直接返回
            return null;
        }
        // 4.命中，需要先把json反序列化为对象
        RedisData redisData = JSONUtil.toBean(json, RedisData.class);
        R r = JSONUtil.toBean((JSONObject) redisData.getData(), type);
        LocalDateTime expireTime = redisData.getExpireTime();
        // 5.判断是否过期
        if(expireTime.isAfter(LocalDateTime.now())) {
            // 5.1.未过期，直接返回店铺信息
            return r;
        }
        // 5.2.已过期，需要缓存重建
        // 6.缓存重建
        // 6.1.获取互斥锁
        String lockKey = LOCK_SHOP_KEY + id;
        boolean isLock = tryLock(lockKey);
        // 6.2.判断是否获取锁成功
        if (isLock){
            // 6.3.成功，开启独立线程，实现缓存重建
            CACHE_REBUILD_EXECUTOR.submit(() -> {
                try {
                    // 查询数据库
                    R newR = dbFallback.apply(id);
                    // 重建缓存
                    this.setWithLogicalExpire(key, newR, time, unit);
                } catch (Exception e) {
                    throw new RuntimeException(e);
                }finally {
                    // 释放锁
                    unlock(lockKey);
                }
            });
        }
        // 6.4.返回过期的商铺信息
        return r;
    }

    public <R, ID> R queryWithMutex(
            String keyPrefix, ID id, Class<R> type, Function<ID, R> dbFallback, Long time, TimeUnit unit) {
        String key = keyPrefix + id;
        // 1.从redis查询商铺缓存
        String shopJson = stringRedisTemplate.opsForValue().get(key);
        // 2.判断是否存在
        if (StrUtil.isNotBlank(shopJson)) {
            // 3.存在，直接返回
            return JSONUtil.toBean(shopJson, type);
        }
        // 判断命中的是否是空值
        if (shopJson != null) {
            // 返回一个错误信息
            return null;
        }

        // 4.实现缓存重建
        // 4.1.获取互斥锁
        String lockKey = LOCK_SHOP_KEY + id;
        R r = null;
        try {
            boolean isLock = tryLock(lockKey);
            // 4.2.判断是否获取成功
            if (!isLock) {
                // 4.3.获取锁失败，休眠并重试
                Thread.sleep(50);
                return queryWithMutex(keyPrefix, id, type, dbFallback, time, unit);
            }
            // 4.4.获取锁成功，根据id查询数据库
            r = dbFallback.apply(id);
            // 5.不存在，返回错误
            if (r == null) {
                // 将空值写入redis
                stringRedisTemplate.opsForValue().set(key, "", CACHE_NULL_TTL, TimeUnit.MINUTES);
                // 返回错误信息
                return null;
            }
            // 6.存在，写入redis
            this.set(key, r, time, unit);
        } catch (InterruptedException e) {
            throw new RuntimeException(e);
        }finally {
            // 7.释放锁
            unlock(lockKey);
        }
        // 8.返回
        return r;
    }

    private boolean tryLock(String key) {
        Boolean flag = stringRedisTemplate.opsForValue().setIfAbsent(key, "1", 10, TimeUnit.SECONDS);
        return BooleanUtil.isTrue(flag);
    }

    private void unlock(String key) {
        stringRedisTemplate.delete(key);
    }
}
```

### 秒杀

- 全局唯一ID

- 秒杀下单超卖

  - 悲观锁 

    用synchronized，lock获取锁，认为线程安全问题一定会发生

  - 乐观锁

    在更新时判断是否有其他线程修改了数据，如果已经修改可以重试或抛异常

- 一人一单

  - 代码块加锁
  - 事务失效，使用代理

- 优化

  - 先利用Redis完成库存余量、一人一单判断，完成抢单业务lua脚本
  - 再将下单业务放入消息队列，利用独立线程异步下单

### 分布式锁

- setnx实现
  - 重入问题
  - 不可重试
  - 超市释放
  - 主从一致性
- Redission分布式锁

### SortedSet实现排行榜

### Set实现关注列表，共同关注intersect

- feed流
  - Timeline
    - 拉模式
    - 推模式
    - 推来结合
  - 智能排序

## rabbitmq

### 交换机

```java
@Bean("xExchange")
public DirectExchange xExchange() {
    return new DirectExchange(X_EXCHANGE);
}
```



### 消息队列

```java
@Bean("queueA")
public Queue queueA() {
    HashMap<String, Object> arguments = new HashMap<>(3);
    arguments.put("x-dead-letter-exchange", Y_DEAD_EXCHANGE);
    arguments.put("x-dead-letter-routing-key", "YD");
    arguments.put("x-message-ttl", 10000);
    return QueueBuilder.durable(QUEUE_A).withArguments(arguments).build();
}
```



### 绑定routingKey

```java
@Bean
public Binding queueABindingX(@Qualifier("queueA") Queue queueA,
                              @Qualifier("xExchange") DirectExchange xExchange) {
    return BindingBuilder.bind(queueA).to(xExchange).with("XA");
}
```



### consumer

```java
@RabbitListener(queues = ConfirmConfig.CONFIRM_QUEUE_NAME)
public void receiveConfirmMessage(Message message) {
    log.info("message content: {}", new String(message.getBody()));
}
```



### producer

```java
rabbitTemplate.convertAndSend(ConfirmConfig.CONFIRM_EXCHANGE_NAME,
                ConfirmConfig.CONFIRM_ROUTING_KEY, message, correlationData);
```



### 基于注解声明交换机、队列、routingkey

首先，需要在启动类上加上 `@EnableRabbit` 注解，开启基于注解的 RabbitMQ 配置。然后，可以使用 `@RabbitListener` 注解来声明一个消息监听器，并使用 `@QueueBinding` 注解来绑定交换机和队列，使用 `@Queue` 注解声明队列，使用 `@Exchange` 注解声明交换机

```java
@RabbitListener(bindings = @QueueBinding(
        value = @Queue(value = "queue-name", durable = "true"),
        exchange = @Exchange(value = "exchange-name", type = "topic"),
        key = "routing-key"
))
public void process(String message) {
    // do something with the message
}

```



## springCloud Alibaba

### 微服务治理

1. 注册发现

   1. eruka
      - eruka-server
        - 引入依赖
        - 启动类```@EnableEurekaServer```
        - 配置文件
      - 服务注册
        - 引入依赖
        - 负载均衡```@LoadBalanced```
        - 修改调用请求链接http://userservice/user/1

   2. Ribbon负载均衡

      - 流程

        - springcloud底层拦截器拦截了RestTemplate请求http://userservice/user/1
        - RibbonLoadBalancerClient会从请求url中获取服务名称，也就是user-service
        - DynamicServerListLoadBalancer根据user-service到eureka拉取服务列表
        - eureka返回列表，localhost:8081、localhost:8082
        - IRule利用内置负载均衡规则，从列表中选择一个，例如localhost:8081
        - RibbonLoadBalancerClient修改请求地址，用localhost:8081替代userservice，得到http://localhost:8081/user/1，发起真实请求

      - 负载均衡策略

        负载均衡的规则都定义在IRule接口中，而IRule有很多不同的实现类：

        | **内置负载均衡规则类**    | **规则描述**                                                 |
        | ------------------------- | ------------------------------------------------------------ |
        | RoundRobinRule            | 简单轮询服务列表来选择服务器。它是Ribbon默认的负载均衡规则。 |
        | AvailabilityFilteringRule | 对以下两种服务器进行忽略：   （1）在默认情况下，这台服务器如果3次连接失败，这台服务器就会被设置为“短路”状态。短路状态将持续30秒，如果再次连接失败，短路的持续时间就会几何级地增加。  （2）并发数过高的服务器。如果一个服务器的并发连接数过高，配置了AvailabilityFilteringRule规则的客户端也会将其忽略。并发连接数的上限，可以由客户端的<clientName>.<clientConfigNameSpace>.ActiveConnectionsLimit属性进行配置。 |
        | WeightedResponseTimeRule  | 为每一个服务器赋予一个权重值。服务器响应时间越长，这个服务器的权重就越小。这个规则会随机选择服务器，这个权重值会影响服务器的选择。 |
        | **ZoneAvoidanceRule**     | 以区域可用的服务器为基础进行服务器的选择。使用Zone对服务器进行分类，这个Zone可以理解为一个机房、一个机架等。而后再对Zone内的多个服务做轮询。 |
        | BestAvailableRule         | 忽略那些短路的服务器，并选择并发数较低的服务器。             |
        | RandomRule                | 随机选择一个可用的服务器。                                   |
        | RetryRule                 | 重试机制的选择逻辑                                           |

   3. Nacos注册中心

      - 安装nacos
      - 引入依赖并配置nacos

2. 远程调用

   openFegin使用步骤

   - 引入依赖

   - 添加注解```@EnableFeignClients```

   - 声明客户端

     ```java
     // 基于注解声明远程调用信息
     @FeignClient("userservice")
     public interface UserClient {
         @GetMapping("/user/{id}")
         User findById(@PathVariable("id") Long id);
     }
     ```

   - 连接池优化性能

     使用**连接池**代替默认的URLConnection

     - URLConnection：默认实现，不支持连接池

     - Apache HttpClient ：支持连接池

     - OKHttp：支持连接池

   

3. 配置管理

   1. nacos中添加配置文件

   2. 引入nacos-config依赖， 添加bootstrap.yaml

   3. 配置热更新

      - 方式一：在@Value注入的变量所在类上添加注解@RefreshScope
      - 方式二：使用@ConfigurationProperties注解代替@Value注解。

   4. 配置的优先级

      服务名-profile.yaml > 服务名.yaml > 本地配置

4. 网关路由

   1. 引入依赖

      ```yaml
      <!--网关-->
      <dependency>
          <groupId>org.springframework.cloud</groupId>
          <artifactId>spring-cloud-starter-gateway</artifactId>
      </dependency>
      <!--nacos服务发现依赖-->
      <dependency>
          <groupId>com.alibaba.cloud</groupId>
          <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
      </dependency>
      ```

   2. 启动类

   3. 配置路由规则

      1. 路由id：路由的唯一标示

      2. 路由目标（uri）：路由的目标地址，http代表固定地址，lb代表根据服务名负载均衡

      3. 路由断言（predicates）：判断路由的规则，

      4. 路由过滤器（filters）：对请求或响应做处理

      ```yaml
      server:
        port: 10010 # 网关端口
      spring:
        application:
          name: gateway # 服务名称
        cloud:
          nacos:
            server-addr: localhost:8848 # nacos地址
          gateway:
            routes: # 网关路由配置
              - id: user-service # 路由id，自定义，只要唯一即可
                # uri: http://127.0.0.1:8081 # 路由的目标地址 http就是固定地址
                uri: lb://userservice # 路由的目标地址 lb就是负载均衡，后面跟服务名称
                predicates: # 路由断言，也就是判断请求是否符合路由规则的条件
                  - Path=/user/** # 这个是按照路径匹配，只要以/user/开头就符合要求
                filters: # 过滤器
              	- AddRequestHeader=Truth, Itcast is freaking awesome! # 添加请求头
      ```

   4. 断言工厂

   5. 过滤器工厂

   6. 解决跨域

      在gateway服务application.yml中添加配置

      ```yaml
      spring:
        cloud:
          gateway:
            # 。。。
            globalcors: # 全局的跨域处理
              add-to-simple-url-handler-mapping: true # 解决options请求被拦截问题
              corsConfigurations:
                '[/**]':
                  allowedOrigins: # 允许哪些网站的跨域请求 
                    - "http://localhost:8090"
                  allowedMethods: # 允许的跨域ajax的请求方式
                    - "GET"
                    - "POST"
                    - "DELETE"
                    - "PUT"
                    - "OPTIONS"
                  allowedHeaders: "*" # 允许在请求中携带的头信息
                  allowCredentials: true # 是否允许携带cookie
                  maxAge: 360000 # 这次跨域检测的有效期
      ```

      

### 微服务保护

​	sentinel

1. 流量控制
2. 系统保护
3. 熔断降级
4. 服务授权

### 分布式事务

​	seata

### 分布式缓存

## docker

## elasticsearch

### 操作索引库

1. 初始化RestClient

   1. 引入依赖

      ```xml
      <dependency>
          <groupId>org.elasticsearch.client</groupId>
          <artifactId>elasticsearch-rest-high-level-client</artifactId>
      </dependency>
      ```

   2. 初始化RestHighLevelClient

      ```java
      RestHighLevelClient client = new RestHighLevelClient(RestClient.builder(
              HttpHost.create("http://192.168.150.101:9200")
      ));
      ```

2. 创建索引库

   1. 创建Request对象
   2. 添加请求参数
   3. 发送请求

   ```java
   // 1.创建Request对象
   CreateIndexRequest request = new CreateIndexRequest("hotel");
   // 2.准备请求的参数：DSL语句
   request.source(MAPPING_TEMPLATE, XContentType.JSON);
   // 3.发送请求
   client.indices().create(request, RequestOptions.DEFAULT);
   ```

   

3. 删除索引库

   ```java
   // 1.创建Request对象
   DeleteIndexRequest request = new DeleteIndexRequest("hotel");
   // 2.发送请求
   client.indices().delete(request, RequestOptions.DEFAULT);
   ```

   

4. 判断索引库是否存在

   ```java
   // 1.创建Request对象
   GetIndexRequest request = new GetIndexRequest("hotel");
   // 2.发送请求
   boolean exists = client.indices().exists(request, RequestOptions.DEFAULT);
   ```

   ​	

#### 总结：

- 核心是client.indices() 方法获取索引库的操作对象
- 初始化client后，构建相应的请求对象（create时还要dsl），发送请求

### 操作文档

#### 新增文档

1. 文档实体类

2. 新增文档DSL

   ```json
   POST /{索引库名}/_doc/1
   {
       "name": "Jack",
       "age": 21
   }
   ```

3. java代码

   ```java
   IndexRequest request = new IndexRequest("indexName").id(1);
   //dsl中的json部分
   request.source(json, XContentType.JSON);
   client.index(request, RequestOptions.DEFAULT);
   ```

4. 步骤

   - 创建request对象
   - 准备请求参数
   - 发送请求（不需要client.indices())

#### 查询文档

1. DSL

   ```json
   GET /{INDEX}/_doc/{ID}
   ```

2. 准备request对象

   ```java
   GetRequest request = new GetRequest("INDEX", "ID");
   ```

3. 发送请求

   ```java
   client.get(request, RequestOptions.DEFAULT);
   ```

4. 解析结果

   结果是一个JSON，其中文档放在一个`_source`属性中，因此解析就是拿到`_source`，反序列化为Java对象即可

   ```java
   json = response.getSourceAsString()
   ```

#### 删除文档

 1. DSL

    ```json
    DELETE /hotel/_doc/{id}
    ```

2. 准备request对象（DeleteRequest）
3. 发送请求（client.delete)

#### 修改文档

1. 全量修改或增量修改

2. RestClient 全量修改的api和新增的api一样

3. 增量修改

   ```java
   UpdateRequest request = new UpdateRequest("indexName", "1");
   request.doc(
              "key", "value"
   		   "key", "value");
   client.update(request, RequestOption.DEFAULT);
   ```

   

#### 批处理

批量处理BulkRequest，其本质就是将多个普通的CRUD请求组合在一起发送。

```java
BulkRequest request = new BulkRequest();
request.add(new IndexRequest("hotel")
                    .id(hotelDoc.getId().toString())
                    .source(JSON.toJSONString(hotelDoc), XContentType.JSON));
// ...
client.bulk(request, RequestOptions.DEFAULT);
```

### 文档搜索

#### match_all 查询

1. 创建SearchRequest对象

2. 准备Request.source()，也就是DSL。

   ① QueryBuilders来构建查询条件

   ② 传入Request.source() 的 query() 方法

3. 发送请求，得到结果

4. 解析结果（参考JSON结果，从外到内，逐层解析）

   ```java
   // 1.准备Request
   SearchRequest request = new SearchRequest("hotel");
   // 2.准备DSL
   request.source()
       .query(QueryBuilders.matchAllQuery());
   // 3.发送请求
   SearchResponse response = client.search(request, RequestOptions.DEFAULT);
   ```

#### match 查询

全文检索的match和multi_match查询与match_all的API基本一致。差别是查询条件，也就是query的部分。

```java
 request.source()
        .query(QueryBuilders.matchQuery("FIELD", "word"));
```

#### 精确查询

- term：词条精确匹配
- range：范围查询

```java
QueryBuilders.termQuery("FIELD", "word")
QueryBuilders.rangeQuery("FIELD", "word")
```

#### 布尔查询

布尔查询是用must、must_not、filter等方式组合其它查询

```java
BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();
boolQuery.must(QueryBuilder.termQuery("FIELD", "word"));
```

#### 排序分页

```java
request.source().sort("price", SortOrder.ASC).from((page - 1) * size).size(5)
```

#### 高亮

```java
request.source().highlighter(new HighlightBuilder().field("name").requireFieldMatch(false));
```

#### 算分控制

```java
// 算分控制
FunctionScoreQueryBuilder functionScoreQuery =
    QueryBuilders.functionScoreQuery(
    // 原始查询，相关性算分的查询
    boolQuery,
    // function score的数组
    new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{
        // 其中的一个function score 元素
        new FunctionScoreQueryBuilder.FilterFunctionBuilder(
            // 过滤条件
            QueryBuilders.termQuery("isAD", true),
            // 算分函数
            ScoreFunctionBuilders.weightFactorFunction(10)
        )
    });
request.source().query(functionScoreQuery);
```

### 数据聚合

#### 聚合种类

- 桶聚合

  - TermAggregation：按照文档字段值分组，例如按照品牌值分组、按照国家分组
  - Date Histogram：按照日期阶梯分组，例如一周为一组，或者一月为一组

- 度量聚合

  - Avg：求平均值
  - Max：求最大值
  - Min：求最小值
  - Stats：同时求max、min、avg、sum等

- 管道聚合

  其它聚合的结果为基础做聚合

> **注意：**参加聚合的字段必须是keyword、日期、数值、布尔类型

#### DSL实现聚合

1. Bucket聚合语法

   ```json
   GET /hotel/_search
   {
     "query": { // 可选，用于限定范围
       "range": {
         "price": {
           "lte": 200 // 只对200元以下的文档聚合
         }
       }
     }, 
     "size": 0,  // 设置size为0，结果中不包含文档，只包含聚合结果
     "aggs": { // 定义聚合
       "brandAgg": { //给聚合起个名字
         "terms": { // 聚合的类型，按照品牌值聚合，所以选择term
           "field": "brand", // 参与聚合的字段
           "order": {
             "_count": "asc" // 按照_count升序排列
           }
           "size": 20 // 希望获取的聚合结果数量
         }
       }
     }
   }
   ```

2. Metric聚合语法

   ```json
   GET /hotel/_search
   {
     "size": 0, 
     "aggs": {
       "brandAgg": { 
         "terms": { 
           "field": "brand", 
           "size": 20
         },
         "aggs": { // 是brands聚合的子聚合，也就是分组后对每组分别计算
           "score_stats": { // 聚合名称
             "stats": { // 聚合类型，这里stats可以计算min、max、avg等
               "field": "score" // 聚合字段，这里是score
             }
           }
         }
       }
     }
   }
   ```

聚合必须的三要素：

- 聚合名称
- 聚合类型
- 聚合字段

聚合可配置属性有：

- size：指定聚合结果数量
- order：指定聚合结果排序方式
- field：指定聚合字段

#### RestAPI实现聚合

```java
request.source().aggregation(AggregationBuilders
                             .terms("brandAgg")
                             .field("brand")
                             .size(100)
                            );
```

### 自动补全查询

elasticsearch提供了[Completion Suggester](https://www.elastic.co/guide/en/elasticsearch/reference/7.6/search-suggesters.html)查询来实现自动补全功能。这个查询会匹配以用户输入内容开头的词条并返回。为了提高补全查询的效率，对于文档中字段的类型有一些约束：

- 参与补全查询的字段必须是completion类型。

- 字段的内容一般是用来补全的多个词条形成的数组。

```json
PUT test
{
  "mappings": {
    "properties": {
      "title":{
        "type": "completion"
      }
    }
  }
}
```

查询的DSL语句如下：

```json
// 自动补全查询
GET /test/_search
{
  "suggest": {
    "title_suggest": {
      "text": "s", // 关键字
      "completion": {
        "field": "title", // 补全查询的字段
        "skip_duplicates": true, // 跳过重复的
        "size": 10 // 获取前10条结果
      }
    }
  }
}
```

RestApi

```java
// 1.准备Request
SearchRequest request = new SearchRequest("hotel");
// 2.准备DSL
request.source().suggest(new SuggestBuilder().addSuggestion(
    "suggestions",
    SuggestBuilders.completionSuggestion("suggestion")
    .prefix(prefix) //查询prefix
    .skipDuplicates(true)
    .size(10)
));

// 3.发起请求
SearchResponse response = client.search(request, RequestOptions.DEFAULT);
// 4.解析结果
Suggest suggest = response.getSuggest();
```

### 数据同步

### 集群

* 集群（cluster）：一组拥有共同的 cluster name 的 节点。

* <font color="red">节点（node)</font>   ：集群中的一个 Elasticearch 实例

* <font color="red">分片（shard）</font>：索引可以被拆分为不同的部分进行存储，称为分片。在集群环境下，一个索引的不同分片可以拆分到不同的节点中